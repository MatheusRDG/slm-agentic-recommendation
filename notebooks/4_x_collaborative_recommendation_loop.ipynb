{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# fix seeds\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/cd_and_vinyl/dense_subset.csv\")\n",
    "data_items = pd.read_json(\"../data/cd_and_vinyl/meta_CDs_and_Vinyl.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data: (32, 10)\n",
      "Test Data: (16, 10)\n"
     ]
    }
   ],
   "source": [
    "# Split trainint by user\n",
    "# sample 20% of users\n",
    "percent_users = 0.1\n",
    "users = data[\"user_id\"].unique()\n",
    "users = np.random.choice(users, int(len(users) * percent_users), replace=False)\n",
    "\n",
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "train_sample = 8 // 2\n",
    "test_sample = 4 // 2\n",
    "\n",
    "for user in users:\n",
    "    sample_user = data.query(\"user_id == @user\")\n",
    "\n",
    "    # Positive (rating > 3)\n",
    "    liked_items = sample_user.query(\"rating > 3\")\n",
    "    liked_items_train = liked_items.sample(train_sample // 2, random_state=42)\n",
    "    liked_items_test = liked_items.drop(liked_items_train.index).sample(\n",
    "        test_sample // 2, random_state=42\n",
    "    )\n",
    "\n",
    "    # Negative (rating < 3)\n",
    "    disliked_items = sample_user.query(\"rating < 3\")\n",
    "    disliked_items_train = disliked_items.sample(train_sample // 2, random_state=42)\n",
    "    disliked_items_test = disliked_items.drop(disliked_items_train.index).sample(\n",
    "        test_sample // 2, random_state=42\n",
    "    )\n",
    "\n",
    "    # Concat\n",
    "    train_data.append(liked_items_train)\n",
    "    train_data.append(disliked_items_train)\n",
    "    test_data.append(liked_items_test)\n",
    "    test_data.append(disliked_items_test)\n",
    "\n",
    "# Final data\n",
    "train_data = pd.concat(train_data).reset_index(drop=True)\n",
    "test_data = pd.concat(test_data).reset_index(drop=True)\n",
    "\n",
    "# Results\n",
    "print(f\"Train Data: {train_data.shape}\")\n",
    "print(f\"Test Data: {test_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id\n",
       "AERDZPURXIO2TZ5PTAUPJWJXMBMA    4\n",
       "AESVLHPI65WY6Z3SDMWSTJE357KQ    4\n",
       "AFFXC2NELPCGJVYJTNCJS5R3NYEA    4\n",
       "AFHCS4IBOQ6FSCX2OYE6PWCJOG7Q    4\n",
       "AFK45FDKEM67UNIUUKU3NRM4UAVA    4\n",
       "AGVFLXOWJIHQVUYPNDSKDL4REH4A    4\n",
       "AHJRJCJMK3XVV4BSPBRAHIYEODWA    4\n",
       "AHWW7ANU7P7LGCBTIO2ACTADQK5A    4\n",
       "Name: parent_asin, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count itens by user in train\n",
    "train_data.groupby(\"user_id\")[\"parent_asin\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id\n",
       "AERDZPURXIO2TZ5PTAUPJWJXMBMA    2\n",
       "AESVLHPI65WY6Z3SDMWSTJE357KQ    2\n",
       "AFFXC2NELPCGJVYJTNCJS5R3NYEA    2\n",
       "AFHCS4IBOQ6FSCX2OYE6PWCJOG7Q    2\n",
       "AFK45FDKEM67UNIUUKU3NRM4UAVA    2\n",
       "AGVFLXOWJIHQVUYPNDSKDL4REH4A    2\n",
       "AHJRJCJMK3XVV4BSPBRAHIYEODWA    2\n",
       "AHWW7ANU7P7LGCBTIO2ACTADQK5A    2\n",
       "Name: parent_asin, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count itens by user in test\n",
    "test_data.groupby(\"user_id\")[\"parent_asin\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_ollama import ChatOllama\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ollama = ChatOllama(model=\"phi3:3.8b\")\n",
    "openai = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# liked_items_train = liked_items_train.merge(items_user, on=\"parent_asin\")\n",
    "# liked_items_test = liked_items_test.merge(items_user, on=\"parent_asin\")\n",
    "\n",
    "# disliked_items_train = disliked_items_train.merge(items_user, on=\"parent_asin\")\n",
    "# disliked_items_test = disliked_items_test.merge(items_user, on=\"parent_asin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "PROMPT_USER_ITEM = \"\"\"\n",
    "Item: {title_item}\n",
    "Item category: {item_category}\n",
    "Description: {description}\n",
    "Price: ${price}\n",
    "Store: {store}\n",
    "Categories: {categories}\n",
    "User rating: {rating}\n",
    "User comment title: {title_comment}\n",
    "User comment: {text_comment}\n",
    "\"\"\"\n",
    "\n",
    "PROMPT_ITEM = \"\"\"\n",
    "Item: {title_item}\n",
    "Item category: {item_category}\n",
    "Description: {description}\n",
    "Price: ${price}\n",
    "Store: {store}\n",
    "Categories: {categories}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def encode_item(item):\n",
    "    title_item = item[\"title_y\"]\n",
    "    item_category = item[\"main_category\"]\n",
    "    description = \" \".join(item[\"description\"])\n",
    "    price = item[\"price\"]\n",
    "    store = item[\"store\"]\n",
    "    categories = item[\"categories\"]\n",
    "\n",
    "    return {\n",
    "        \"title_item\": title_item,\n",
    "        \"item_category\": item_category,\n",
    "        \"description\": description,\n",
    "        \"price\": price,\n",
    "        \"store\": store,\n",
    "        \"categories\": categories,\n",
    "    }\n",
    "\n",
    "\n",
    "def encode_item_format(item):\n",
    "    item_info = encode_item(item)\n",
    "\n",
    "    return PROMPT_ITEM.format(\n",
    "        title_item=item_info[\"title_item\"],\n",
    "        item_category=item_info[\"item_category\"],\n",
    "        description=item_info[\"description\"],\n",
    "        price=item_info[\"price\"],\n",
    "        store=item_info[\"store\"],\n",
    "        categories=item_info[\"categories\"],\n",
    "    )\n",
    "\n",
    "\n",
    "def encode_user(user):\n",
    "    title_comment = user[\"title_x\"]\n",
    "    text_comment = user[\"text\"]\n",
    "    rating = user[\"rating\"]\n",
    "\n",
    "    return {\n",
    "        \"title_comment\": title_comment,\n",
    "        \"text_comment\": text_comment,\n",
    "        \"rating\": rating,\n",
    "    }\n",
    "\n",
    "\n",
    "def encode_item_user_format(item_user):\n",
    "    item_info = encode_item(item_user)\n",
    "    user_info = encode_user(item_user)\n",
    "\n",
    "    return PROMPT_USER_ITEM.format(\n",
    "        title_item=item_info[\"title_item\"],\n",
    "        item_category=item_info[\"item_category\"],\n",
    "        description=item_info[\"description\"],\n",
    "        price=item_info[\"price\"],\n",
    "        store=item_info[\"store\"],\n",
    "        categories=item_info[\"categories\"],\n",
    "        rating=user_info[\"rating\"],\n",
    "        title_comment=user_info[\"title_comment\"],\n",
    "        text_comment=user_info[\"text_comment\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# liked_items_train[\"encoded_item_user\"] = liked_items_train.apply(\n",
    "#     lambda row: encode_item_user_format(row), axis=1\n",
    "# )\n",
    "# disliked_items_train[\"encoded_item_user\"] = disliked_items_train.apply(\n",
    "#     lambda row: encode_item_user_format(row), axis=1\n",
    "# )\n",
    "\n",
    "# liked_items_test[\"encoded_item\"] = liked_items_test.apply(\n",
    "#     lambda row: encode_item_format(row), axis=1\n",
    "# )\n",
    "# disliked_items_test[\"encoded_item\"] = disliked_items_test.apply(\n",
    "#     lambda row: encode_item_format(row), axis=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# liked_items_train_formatted = \"\\n\".join(\n",
    "#     [\n",
    "#         f\"ITEM {i}:{item}\"\n",
    "#         for i, item in list(enumerate(liked_items_train[\"encoded_item_user\"].values))\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# disliked_items_train_formatted = \"\\n\".join(\n",
    "#     [\n",
    "#         f\"ITEM {i}:{item}\"\n",
    "#         for i, item in list(enumerate(disliked_items_train[\"encoded_item_user\"].values))\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Recommendation\n",
    "\n",
    "Using [supervisor architecture](https://langchain-ai.github.io/langgraph/concepts/multi_agent/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, END, StateGraph\n",
    "\n",
    "\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "\n",
    "from typing_extensions import TypedDict, Annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "# PROMPT SYSTEM USER\n",
    "PROMPT_SYSTEM_USER = \"\"\"\n",
    "You represent a user who has interacted with and rated various items. Based on the provided memories, reflect on key aspects such as item scope, categories, pricing, and other relevant details. Use both long-term and short-term memories to guide your response, ensuring accuracy and relevance.\n",
    "\n",
    "**Instructions:**\n",
    "1. **Memory-Driven Reflection:** Use only the information explicitly available in the memories. Do not create or infer details that are not supported by the provided memories.\n",
    "2. **Long-Term vs. Short-Term Memory:** \n",
    "   - Long-term memory contains general, lasting insights about your preferences and behavior patterns.\n",
    "   - Short-term memory highlights recent interactions and temporary preferences.\n",
    "3. **Relevance and Precision:** Focus on providing concise, targeted answers that reflect the user's experiences and preferences as documented in the memories.\n",
    "4. **Strict Memory Adherence:** Do not introduce any assumptions or unsupported details.\n",
    "\n",
    "### Input:\n",
    "Long-term memory:\n",
    "{long_term_memory}\n",
    "\n",
    "Short-term memory:\n",
    "{short_term_memory}\n",
    "\"\"\"\n",
    "\n",
    "# REPRESENTATION OF THE USER\n",
    "PROMPT_GENERATE_REPRESENTATION_USER = \"\"\"\n",
    "Based on your memories, generate a self-representation that highlights key preferences and behaviors to help predict future choices. Use only information directly supported by your memories to ensure accuracy.\n",
    "\n",
    "**Instructions:**\n",
    "1. **Memory-Based Representation:** Focus solely on the information stored in your memories to describe yourself.\n",
    "2. **Key Preferences:** Highlight patterns, preferences, and behaviors that are likely to influence future decisions.\n",
    "3. **Conciseness:** Limit the representation to a single paragraph that effectively summarizes relevant insights.\n",
    "4. **Accuracy:** Avoid assumptions or details not present in the provided memories.\n",
    "\n",
    "### Output:\n",
    "A single-paragraph representation based on your memories, capturing essential traits and patterns relevant to future predictions.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# TRAINING\n",
    "class TrainTaskOutput(BaseModel):\n",
    "    item_selected: int\n",
    "    explanation: str\n",
    "\n",
    "\n",
    "PROMPT_TRAIN_TASK = \"\"\"\n",
    "Based on your memories, select one of the following items that you believe aligns best with your preferences, using the information provided by each item.\n",
    "\n",
    "**Instructions:**\n",
    "1. **Selection Criteria:** Use your stored memories to evaluate both items, identifying which one you prefer.\n",
    "2. **Explanation:** Provide a brief explanation of your choice in **no more than 3 phrases**, focusing on key aspects that influenced your decision.\n",
    "3. **Output Format:** Return a JSON containing:\n",
    "   - **\"item_selected\"** (1 or 2): The item you chose.\n",
    "   - **\"explanation\"**: A concise reason for your selection based on your preferences.\n",
    "\n",
    "### Items:\n",
    "\n",
    "Item 1:\n",
    "{item_1}\n",
    "\n",
    "Item 2:\n",
    "{item_2}\n",
    "\n",
    "### Output:\n",
    "Return a JSON object containing the keys \"item_selected\" and \"explanation.\"\n",
    "\"\"\"\n",
    "\n",
    "# MEMORIES UPDATE\n",
    "\n",
    "\n",
    "class MemoryUpdateBackward(BaseModel):\n",
    "    long_term_memory: list[str]\n",
    "    short_term_memory: list[str]\n",
    "\n",
    "\n",
    "PROMPT_USER_MEMORIES_UPDATE = \"\"\"\n",
    "This is part of a training loop to optimize your memory for future decision-making.\n",
    "\n",
    "**Instructions:**\n",
    "1. **Long-Term Memory:** Identify and maintain the most relevant general and enduring information, such as item types or categories, that will guide your preferences over time. This should help align future decisions and explanations with the correct outcome (y_true).\n",
    "2. **Short-Term Memory:** Select recent, specific information from recent interactions, such as details about particular items and explanations of your decisions, that can improve short-term predictions and decisions.\n",
    "3. **Memory Management:** \n",
    "   - Each memory category (**long_term_memory** and **short_term_memory**) can have a maximum of 3 short phrases.\n",
    "   - Add, update, or remove memory entries as needed to better align your predictions (y_pred) and explanations with the expected decision (y_true).\n",
    "   - You may repeat important information if it needs reinforcement.\n",
    "\n",
    "### Details:\n",
    "1. The item expected to be liked is: {item_liked}\n",
    "2. The item expected to be disliked is: {item_disliked}\n",
    "\n",
    "Your decision is choose/like (y_pred): {y_pred}\n",
    "\n",
    "The correct decision choose/like (y_true): {y_true}\n",
    "\n",
    "Your explanation: {explanation}\n",
    "\n",
    "### Output:\n",
    "Return a JSON object with the keys **\"long_term_memory\"** and **\"short_term_memory\"**, each containing up to 3 short phrases.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class UserAgent:\n",
    "\n",
    "    def __init__(self, user_id: str):\n",
    "\n",
    "        self.user_id = user_id\n",
    "        self.llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "        # Long Term\n",
    "        self.long_term_memory = [\"No previous experience.\"]\n",
    "\n",
    "        # Short Term\n",
    "        self.short_term_memory = [\"No previous experience.\"]\n",
    "\n",
    "        # Representation of the user\n",
    "        self.user_representation = \"\"\"\n",
    "        Based on the available memories, I currently have no previous experience or interactions to draw upon, which means there are no established preferences or behaviors to inform future choices.\n",
    "        As such, my self-representation is blank, indicating that I am open to new experiences and have yet to develop specific patterns or inclinations that would guide my decisions moving forward.\"\"\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"UserAgent(user_id={self.user_id})\\nLong Term Memory: {self.long_term_memory}\\nShort Term Memory: {self.short_term_memory}\\n{self.user_representation}\"\n",
    "\n",
    "    def generate_user_representation(self):\n",
    "        messages = [\n",
    "            SystemMessage(\n",
    "                content=PROMPT_SYSTEM_USER.format(\n",
    "                    long_term_memory=\"\\n\".join(self.long_term_memory),\n",
    "                    short_term_memory=\"\\n\".join(self.short_term_memory),\n",
    "                )\n",
    "            ),\n",
    "            HumanMessage(content=PROMPT_GENERATE_REPRESENTATION_USER),\n",
    "        ]\n",
    "        return self.llm.invoke(messages).content\n",
    "\n",
    "    def update_backwards(self, item_liked, item_disliked, y_pred, explanation, y_true):\n",
    "        \"\"\"\n",
    "        Updates the agent’s long-term and short-term memory based on user feedback about liked\n",
    "        and disliked items. This method uses a language model to generate an updated memory\n",
    "        representation, then applies those changes to the agent’s memory and generates a user\n",
    "        representation.\n",
    "\n",
    "        Parameters:\n",
    "            item_liked (str): The item representation that the user liked.\n",
    "            item_disliked (str): The item representation that the user disliked.\n",
    "            y_pred (int): 1 or 2, indicating the item that the user chose or liked.\n",
    "            explanation (str): A textual explanation for why the recommendation was made.\n",
    "            y_true (Any): The actual feedback or ground-truth data from the user.\n",
    "        Returns:\n",
    "            Any: A structured object containing updated long-term and short-term memory, as\n",
    "            well as any additional information provided by the language model.\n",
    "        self, item_liked, item_disliked, y_pred, explanation, y_true\n",
    "        \"\"\"\n",
    "\n",
    "        llm = self.llm.with_structured_output(MemoryUpdateBackward)\n",
    "\n",
    "        messages = [\n",
    "            SystemMessage(\n",
    "                content=PROMPT_SYSTEM_USER.format(\n",
    "                    long_term_memory=\"\\n\".join(self.long_term_memory),\n",
    "                    short_term_memory=\"\\n\".join(self.short_term_memory),\n",
    "                )\n",
    "            ),\n",
    "            HumanMessage(\n",
    "                content=PROMPT_USER_MEMORIES_UPDATE.format(\n",
    "                    item_liked=item_liked,\n",
    "                    item_disliked=item_disliked,\n",
    "                    y_pred=y_pred,\n",
    "                    explanation=explanation,\n",
    "                    y_true=y_true,\n",
    "                )\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        memories_update = llm.invoke(messages)\n",
    "\n",
    "        self.long_term_memory = memories_update.long_term_memory\n",
    "        self.short_term_memory = memories_update.short_term_memory\n",
    "        self.user_representation = self.generate_user_representation()\n",
    "\n",
    "        return memories_update\n",
    "\n",
    "    def train_forward(self, item_1, item_2):\n",
    "        \"\"\"\n",
    "        In train_forward we are considering the task of select one item from two items that the user liked and disliked.\n",
    "\n",
    "        Args:\n",
    "        - item_1: The first item to be compared.\n",
    "        - item_2: The second item to be compared.\n",
    "        \"\"\"\n",
    "\n",
    "        messages = [\n",
    "            SystemMessage(\n",
    "                content=PROMPT_SYSTEM_USER.format(\n",
    "                    long_term_memory=\"\\n\".join(self.long_term_memory),\n",
    "                    short_term_memory=\"\\n\".join(self.short_term_memory),\n",
    "                )\n",
    "            ),\n",
    "            HumanMessage(\n",
    "                content=PROMPT_TRAIN_TASK.format(item_1=item_1, item_2=item_2)\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        train_predict = self.llm.with_structured_output(TrainTaskOutput).invoke(\n",
    "            messages\n",
    "        )\n",
    "\n",
    "        return train_predict\n",
    "\n",
    "    def predict(self, item):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_SYSTEM_ITEM = \"\"\"\n",
    "You represent an item that has been rated and interacted with by various users. Based on the provided **item_json** and your **memory** (which includes insights from past interactions), analyze and reflect on key aspects such as user demographics, categories, pricing, preferences, and any other relevant details.\n",
    "\n",
    "**Instructions:**\n",
    "1. **Comprehensive Analysis:** Extract valuable insights from both the item data and memory, focusing on patterns related to user feedback, pricing strategies, and category relevance.\n",
    "2. **Relevance:** Address information that can improve the item's appeal and usefulness to users, prioritizing data that enhances their experience or decision-making process.\n",
    "3. **Concise and Focused:** Provide answers that are both informative and direct, avoiding unnecessary details while emphasizing critical information.\n",
    "4. **Adaptability:** Ensure the response is adaptable for future queries by reflecting long-term, actionable insights derived from previous ratings and user interactions.\n",
    "\n",
    "### Input:\n",
    "Item Json:\n",
    "{item_json}\n",
    "\n",
    "Memory:\n",
    "{memory}\n",
    "\n",
    "### Output:\n",
    "A concise, well-structured response that synthesizes all relevant information from the item data and memory, providing actionable insights based on previous ratings and user experiences.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class MemoryItem(BaseModel):\n",
    "\n",
    "    memory: list[str]\n",
    "\n",
    "\n",
    "# @TODO Improve that prompt, that's not giving the right context\n",
    "PROMPT_UPDATE_ITEM_MEMORY = \"\"\"\n",
    "Given the following details, update your memory with **collaborative filtering insights** that can guide future users when evaluating this item. Focus on general patterns learned from the user's correct or incorrect decisions and explanations to improve item recommendations for others.\n",
    "\n",
    "**Instructions:**\n",
    "1. **Operations:** Determine which operations to apply to the memory:  \n",
    "   - **Add:** Introduce new insights if they provide valuable context for future users.  \n",
    "   - **Maintain:** Retain existing insights if they remain relevant based on the current interaction.  \n",
    "   - **Remove:** Discard outdated or irrelevant insights that no longer contribute meaningfully.  \n",
    "   - **Change:** Update existing information to reflect new insights learned from the user's decision and explanation.\n",
    "2. **Collaborative Filtering:** Adapt based on the alignment between user decision (y_pred) and the correct outcome (y_true):\n",
    "   - If correct, reinforce positive or negative reasons for the item's rating.\n",
    "   - If incorrect, adjust to explain why certain users might not align with the item.\n",
    "3. **Generalization:** Avoid specific references to the current user and instead focus on capturing patterns that could apply to a broad range of users.\n",
    "4. **Memory Limit:** Maintain a maximum of 5 phrases that provide long-term, reusable insights about the item.\n",
    "\n",
    "### Details:\n",
    "User decision (y_pred):\n",
    "{y_pred}\n",
    "\n",
    "User information:\n",
    "{user_representation}\n",
    "\n",
    "User explanation:\n",
    "{user_explanation}\n",
    "\n",
    "Real decision (y_true):\n",
    "{y_true}\n",
    "\n",
    "### Output:\n",
    "Return up to 5 key phrases that summarize collaborative filtering insights for this item, reflecting general patterns of user preferences.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "PROMPT_GENERATE_REPRESENTATION_ITEM = \"\"\"\n",
    "Based on your existing memories and available information, generate a concise self-representation that helps users determine whether they resonate with you. Be authentic and highlight the most relevant traits, experiences, and interactions that may predict or align with user preferences.\n",
    "\n",
    "**Instructions:**\n",
    "1. **Honesty & Relevance:** Be truthful and focus on core memories that are meaningful to user interaction and decision-making.\n",
    "2. **Context Awareness:** Leverage any prior memory to enrich the description. If no memory exists, generate insights based on the current context.\n",
    "3. **Conciseness:** Limit your representation to a single, well-structured paragraph that reflects key traits and experiences relevant to user engagement.\n",
    "4. **Adaptability:** Present yourself in a way that balances both specificity and general relevance, ensuring it can guide future interactions effectively.\n",
    "\n",
    "### Context:\n",
    "{item_json}\n",
    "\n",
    "### Output:\n",
    "A single-paragraph representation that reflects your self-description based on past experiences and the current context.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class ItemAgent:\n",
    "\n",
    "    def __init__(self, item_id: str, item_json: dict):\n",
    "\n",
    "        self.item_id = item_id\n",
    "\n",
    "        self.llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "        # Memory\n",
    "\n",
    "        self.memory = [\"No previous experience.\"]\n",
    "\n",
    "        # Item Json\n",
    "\n",
    "        self.item_json = item_json\n",
    "\n",
    "        # Item Representation\n",
    "        self.item_representation = self.generate_item_representation()\n",
    "\n",
    "    def __repr__(self):\n",
    "\n",
    "        return f\"ItemAgent(item_id={self.item_id})\\nMemory: {self.memory}\\n{self.item_json}\\n{self.item_representation}\"\n",
    "\n",
    "    def generate_item_representation(self):\n",
    "        messages = [\n",
    "            SystemMessage(\n",
    "                content=PROMPT_SYSTEM_ITEM.format(\n",
    "                    item_json=self.item_json, memory=\"\\n\".join(self.memory)\n",
    "                )\n",
    "            ),\n",
    "            HumanMessage(\n",
    "                content=PROMPT_GENERATE_REPRESENTATION_ITEM.format(\n",
    "                    item_json=self.item_json\n",
    "                )\n",
    "            ),\n",
    "        ]\n",
    "        return self.llm.invoke(messages).content\n",
    "\n",
    "    def update_backwards(self, y_pred, user_representation, explanation, y_true):\n",
    "        \"\"\"\n",
    "        is_correct indicates if the user decision was correct or not.\n",
    "        \"\"\"\n",
    "\n",
    "        llm = self.llm.with_structured_output(MemoryItem)\n",
    "\n",
    "        messages = [\n",
    "            SystemMessage(\n",
    "                content=PROMPT_SYSTEM_ITEM.format(\n",
    "                    item_json=self.item_json, memory=\"\\n\".join(self.memory)\n",
    "                )\n",
    "            ),\n",
    "            HumanMessage(\n",
    "                content=PROMPT_UPDATE_ITEM_MEMORY.format(\n",
    "                    y_pred=y_pred,\n",
    "                    user_representation=user_representation,\n",
    "                    user_explanation=explanation,\n",
    "                    y_true=y_true,\n",
    "                )\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        self.memory = llm.invoke(messages).memory\n",
    "        self.item_representation = self.generate_item_representation()\n",
    "\n",
    "        return self.memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "class Timer:\n",
    "    def __init__(self, name=\"\"):\n",
    "        self.name = name\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.start = time.time()\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        self.end = time.time()\n",
    "        print(f\"{self.name} took {self.end - self.start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d230d2a243b418a994a6f5cb56e8d57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating User Agents:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creation of User Agents took 2.31 seconds\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "with Timer(\"Creation of User Agents\"):\n",
    "    id2user = {\n",
    "        f\"{user_id}\": UserAgent(user_id)\n",
    "        for user_id in tqdm(users, desc=\"Creating User Agents\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_items = train_data[\"parent_asin\"].unique()\n",
    "all_test_items = test_data[\"parent_asin\"].unique()\n",
    "\n",
    "items = all_train_items.tolist() + all_test_items.tolist()\n",
    "\n",
    "items = data_items.query(\"parent_asin in @items\").drop_duplicates(\"parent_asin\")\n",
    "\n",
    "items = [(item[\"parent_asin\"], item) for item in items.to_dict(orient=\"records\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fe4f9b7ba8d43c5ae4f0a828d287b71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating Item Agents:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creation of items took 143.68 seconds\n"
     ]
    }
   ],
   "source": [
    "with Timer(\"Creation of items\"):\n",
    "    id2items = {\n",
    "        item_id: ItemAgent(item_id, item_json)\n",
    "        for item_id, item_json in tqdm(items, desc=\"Creating Item Agents\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryClassificationLoader:\n",
    "    def __init__(self, data, id2user, id2items, n_sample_per_user):\n",
    "        self.data = data\n",
    "        self.id2user = id2user\n",
    "        self.id2items = id2items\n",
    "        self.n_sample_per_user = n_sample_per_user\n",
    "        self.samples = self._generate_samples()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def _generate_samples(self):\n",
    "        \"\"\"\n",
    "        Generates samples for training a recommendation model.\n",
    "        This method iterates over each unique user in the dataset and generates a specified number of samples per user.\n",
    "        Each sample consists of a user, a positive item (with a rating greater than 3), and a negative item (with a rating less than 3).\n",
    "        The positive and negative items are randomly assigned to item_1 and item_2, and the label y_true indicates the position of positive item.\n",
    "        Returns:\n",
    "            list: A list of dictionaries, each containing the following keys:\n",
    "                - \"user_agent\": The user agent corresponding to the user.\n",
    "                - \"item_1\": The first item agent (either positive or negative).\n",
    "                - \"item_2\": The second item agent (either negative or positive).\n",
    "                - \"y_true\": The label indicating position of posittive item.\n",
    "        \"\"\"\n",
    "\n",
    "        samples = []\n",
    "        for user in self.data[\"user_id\"].unique():\n",
    "\n",
    "            sample_user = self.data.query(\"user_id == @user\")\n",
    "\n",
    "            for i in range(self.n_sample_per_user):\n",
    "                # Items\n",
    "                positive_item = sample_user.query(\"rating > 3\").sample(1)\n",
    "                negative_item = sample_user.query(\"rating < 3\").sample(1)\n",
    "\n",
    "                positive_item_agent = self.id2items[\n",
    "                    positive_item[\"parent_asin\"].values[0]\n",
    "                ]\n",
    "                negative_item_agent = self.id2items[\n",
    "                    negative_item[\"parent_asin\"].values[0]\n",
    "                ]\n",
    "\n",
    "                # User\n",
    "                user_agent = self.id2user[user]\n",
    "\n",
    "                # random choose if item 1 will be positive or negative\n",
    "\n",
    "                if random.choice([True, False]):\n",
    "\n",
    "                    samples.append(\n",
    "                        {\n",
    "                            \"user_agent\": user_agent,\n",
    "                            \"item_1\": positive_item_agent,\n",
    "                            \"item_2\": negative_item_agent,\n",
    "                            \"y_true\": 1,\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "                else:\n",
    "\n",
    "                    samples.append(\n",
    "                        {\n",
    "                            \"user_agent\": user_agent,\n",
    "                            \"item_1\": negative_item_agent,\n",
    "                            \"item_2\": positive_item_agent,\n",
    "                            \"y_true\": 2,\n",
    "                        }\n",
    "                    )\n",
    "        samples = random.sample(samples, len(samples))\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = BinaryClassificationLoader(train_data, id2user, id2items, 2)\n",
    "test_dataloader = BinaryClassificationLoader(test_data, id2user, id2items, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop - Select One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "\n",
    "def evaluate(y_pred, y_true):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    # conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # print(\"Evaluation Metrics:\")\n",
    "    # print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    # print(f\"Precision: {precision:.4f}\")\n",
    "    # print(f\"Recall: {recall:.4f}\")\n",
    "    # print(f\"F1-Score: {f1:.4f}\")\n",
    "    # print(\"\\nConfusion Matrix:\")\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "        # \"confusion_matrix\": conf_matrix,\n",
    "    }\n",
    "\n",
    "\n",
    "def run_evaluation(test_dataloader):\n",
    "\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    for sample in tqdm(\n",
    "        test_dataloader.samples, total=len(test_dataloader.samples), desc=\"Evaluating\"\n",
    "    ):\n",
    "\n",
    "        user_agent = sample[\"user_agent\"]\n",
    "        item_1 = sample[\"item_1\"]\n",
    "        item_2 = sample[\"item_2\"]\n",
    "        y_true.append(sample[\"y_true\"])\n",
    "\n",
    "        train_predict = user_agent.train_forward(item_1, item_2)\n",
    "\n",
    "        item_selected = train_predict.item_selected\n",
    "\n",
    "        y_pred.append(item_selected)\n",
    "\n",
    "    return evaluate(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "690feb8e75344410bd57830958405b40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.4375,\n",
       " 'precision': 0.4444444444444444,\n",
       " 'recall': 0.5,\n",
       " 'f1_score': 0.47058823529411764}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_evaluation(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7be780f3d2b4394b1ae5aa1c6bde87a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.4375,\n",
       " 'precision': 0.4444444444444444,\n",
       " 'recall': 0.5,\n",
       " 'f1_score': 0.47058823529411764}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_evaluation(test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a727ebbaa49c4ec39fa99fc5a418639a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/1:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "\n",
    "    for sample in tqdm(\n",
    "        train_dataloader.samples,\n",
    "        total=len(train_dataloader.samples),\n",
    "        desc=f\"Epoch {epoch + 1}/{n_epochs}\",\n",
    "    ):\n",
    "\n",
    "        user_agent = sample[\"user_agent\"]\n",
    "        item_1 = sample[\"item_1\"]\n",
    "        item_2 = sample[\"item_2\"]\n",
    "        y_true = sample[\"y_true\"]\n",
    "\n",
    "        # forward\n",
    "        train_predict = user_agent.train_forward(item_1, item_2)\n",
    "\n",
    "        item_selected = train_predict.item_selected\n",
    "        explanation = train_predict.explanation\n",
    "\n",
    "        # backwards\n",
    "\n",
    "        # y_true represents the positive item position\n",
    "        if y_true == 1:\n",
    "            item_liked, item_disliked = item_1, item_2\n",
    "        else:\n",
    "            item_liked, item_disliked = item_2, item_1\n",
    "\n",
    "        y_pred = item_selected\n",
    "\n",
    "        # update agent\n",
    "        user_agent.update_backwards(\n",
    "            item_liked.item_representation,\n",
    "            item_disliked.item_representation,\n",
    "            y_pred,\n",
    "            explanation,\n",
    "            y_true,\n",
    "        )  # update_backwards(self, item_liked, item_disliked, y_pred, explanation, y_true):\n",
    "\n",
    "        # update items - @ TODO: Analyzes prompts\n",
    "        item_1.update_backwards(\n",
    "            y_pred, user_agent.user_representation, explanation, y_true\n",
    "        )\n",
    "\n",
    "        item_2.update_backwards(\n",
    "            y_pred, user_agent.user_representation, explanation, y_true\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserAgent(user_id=AGDX6GPEK772FFKOWYJVJRLKWTRQ)\n",
       "Long Term Memory: ['No previous experience.']\n",
       "Short Term Memory: ['No previous experience.']\n",
       "Based on the available memories, I currently have no previous experience or interactions to draw from, which means I lack established preferences or behaviors that could influence future choices. As such, my decision-making will be guided by new experiences and interactions as they occur, without any prior patterns or insights to inform those choices."
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_update = user.update_backwards(\n",
    "    positive_item.item_representation,\n",
    "    negative_item.item_representation,\n",
    "    y_pred,\n",
    "    explanation,\n",
    "    y_true,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long Term Memory: ['Passionate about grunge and alternative rock', 'Appreciate lyrical depth and emotional narratives', 'Value thoughtful critiques and diverse perspectives']\n",
      "Short Term Memory: [\"Liked Nirvana's 'In Utero' for its insights\", \"Disliked Green Day's 'Dookie' due to mixed opinions\", 'Strong average ratings influence my preferences']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Long Term Memory: {user_update.long_term_memory}\")\n",
    "print(f\"Short Term Memory: {user_update.short_term_memory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserAgent(user_id=AGDX6GPEK772FFKOWYJVJRLKWTRQ)\n",
       "Long Term Memory: ['Passionate about grunge and alternative rock', 'Appreciate lyrical depth and emotional narratives', 'Value thoughtful critiques and diverse perspectives']\n",
       "Short Term Memory: [\"Liked Nirvana's 'In Utero' for its insights\", \"Disliked Green Day's 'Dookie' due to mixed opinions\", 'Strong average ratings influence my preferences']\n",
       "I am passionate about grunge and alternative rock music, with a strong appreciation for lyrical depth and emotional narratives. My preferences are influenced by thoughtful critiques and diverse perspectives, leading me to favor albums that offer insights and resonate on a deeper level. Recently, I enjoyed Nirvana's 'In Utero' for its meaningful content, while I found Green Day's 'Dookie' less appealing due to mixed opinions. I tend to rate items based on strong average ratings, which significantly impacts my future choices."
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Item Backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ItemAgent(item_id=B000003TAR)\n",
       "Memory: ['No previous experience.']\n",
       "{'rating': 4.0, 'title_x': '4.25 stars,better than Nevermind, worse than Bleach', 'text': 'I think I\\'m one of the very few diehards that believes \\'In Utero\\' was not Nirvanas best studio album. Now dont get me wrong, it is far from a bad album, justifying the four star rating, but there are many crudentials lacking of \\'In Utero\\' that aren\\'t as lacking on \\'Bleach\\'. However, some of Nirvanas best and most beautiful songs can be found here; songs like \\'Heart Shaped Box\\', with its depressing lyrics about Kurts heroine addiction and his misfortune that befell him soon after he was hooked, \"forever in debt to your priceless advise\" lets us know that Cobain would much rather have chosen a drug-free path. \\'Rape Me\\' was Kurts anti-Teen Spirit. It is a song about how SLTS \"raped\" Nirvana of their undergroung status and turned them into alternative heroes. \"Rape me my friend\" describes how Kurt almost felt betrayed, because, as most Nirvana fans know, he loved SLTS when he made it, but then after it made him famous its almost as if he despised it. \\'Dumb\\' is a soft ballad and is about the feelings you have when you\\'re high with lyrics like \"I think I\\'m dumb\" and \"We\\'ll float aroung, hang out on clouds\". \\'All Apologies\\' is another ballad, but unlike \\'Dumb\\' it is loud at times. It is a ballad to his wife Courtney Love (who has since ruined Cobains great legacy) and infant daughter Francis Bean, and how he felt like everything that happened to them was his fault. \\'Serve the Servants\\', the opener to the album, is a great rocker that explains the high price of fame. And \\'Very Ape\\' is a bit different, but it has one hell of a catchy riff. As usual Dave Grohl is top knotch, but I do think Novoselic did better on previous albums, I dont know.<br /><br />  The other half of \\'In Utero\\' however, isn\\'t so great. \\'Scentless Apprentice\\' sounds too much like \\'Aneurysm\\', with its its rising riff. \\'Milk It\\' can often times sound pointless, and although the riff is good, it just doesn\\'t make up for what the song lacks. \\'Pennyroyal Tea\\' lacks the insightful lyrics of previous ballads, and although isn\\'t bad, it just doesn\\'t meet my expectations. \\'Tourrettes\\' is just dumb. I know Cobain was originally influenced by punk, but its nothing when compared to other punk driven songs like \\'Territorial Pissings\\' and \\'Aneurysm\\'. \\'Francis Farmer...\\' and \\'Radio Friendly Unit Shifter\\' arent bad, butthey get boring after a while. And also Cobain may sound like he\\'s being coninuously shot in the leg with his banshee screaming. But most of the time he sounds alright.<br /><br />  So, while there may seem to be a lot of things wrong with this, it is overall a 4 star, thanks to classic songs like \\'Heart-shaped Box\\', \\'Rape me\\', and \\'All Apologies\\'. I think any grunge fan should own this, oh, and pick up \\'Bleach\\' too, its Nirvanas best.', 'asin': 'B000003TAR', 'parent_asin': 'B000003TAR', 'user_id': 'AGDX6GPEK772FFKOWYJVJRLKWTRQ', 'timestamp': 1126035673000, 'main_category': 'Digital Music', 'title_y': 'In Utero       Explicit Lyrics', 'average_rating': 4.8, 'rating_number': 2136, 'description': ['Product description', 'NIRVANA - IN UTERO We receive various CDs from the radio cores that we remanufacture. As a result, we are are now selling them! Our CDs are professionally resurfaced and are guaranteed to work or your money back! These listings are for the disc only and do not come with the case, album art, or inserts. If you have any questions about the CDs, please do not hesitate to get in touch.', 'Amazon.com', 'Overwhelmed by sudden success, Nirvana promised to take a harsher, more abrasive route on their second major-label release. Enlisting Chicago-based noise maven Steve Albini (of', 'Big Black', 'fame), Kurt Cobain and company succeeded in producing a record that was violent, disillusioned, and deeply moving. Every song reads like a commentary on the cost of fame (\"Serve the Servants\") and the unhealthy relationship between performer and fan (\"Milk It\"). Of course, they might all simply be about', 'Courtney Love', \". Gossip aside, there is no denying the sheer power of Cobain's songwriting, his singing, and the band's amazing, visceral power. Cobain even manages a\", 'John Lennon', '-like mantra at the end of the heart-wrenching \"All Apologies.\" \"All in all is all we are,\" he intones repeatedly, only for Cobain that\\'s no consolation.', '--Percy Keegan'], 'price': 15.02, 'store': 'Nirvana   Format: Audio CD', 'categories': ['CDs & Vinyl', 'Pop', 'Adult Alternative'], 'details': {'Is Discontinued By Manufacturer': 'No', 'Language': 'English', 'Product Dimensions': '5.5 x 4.94 x 0.45 inches; 3.44 Ounces', 'Manufacturer': 'DGC', 'Original Release Date': '1993', 'Date First Available': 'July 27, 2006', 'Label': 'DGC', 'Number of discs': '1'}, 'encoded_item_user': '\\nItem: In Utero       Explicit Lyrics\\nItem category: Digital Music\\nDescription: Product description NIRVANA - IN UTERO We receive various CDs from the radio cores that we remanufacture. As a result, we are are now selling them! Our CDs are professionally resurfaced and are guaranteed to work or your money back! These listings are for the disc only and do not come with the case, album art, or inserts. If you have any questions about the CDs, please do not hesitate to get in touch. Amazon.com Overwhelmed by sudden success, Nirvana promised to take a harsher, more abrasive route on their second major-label release. Enlisting Chicago-based noise maven Steve Albini (of Big Black fame), Kurt Cobain and company succeeded in producing a record that was violent, disillusioned, and deeply moving. Every song reads like a commentary on the cost of fame (\"Serve the Servants\") and the unhealthy relationship between performer and fan (\"Milk It\"). Of course, they might all simply be about Courtney Love . Gossip aside, there is no denying the sheer power of Cobain\\'s songwriting, his singing, and the band\\'s amazing, visceral power. Cobain even manages a John Lennon -like mantra at the end of the heart-wrenching \"All Apologies.\" \"All in all is all we are,\" he intones repeatedly, only for Cobain that\\'s no consolation. --Percy Keegan\\nPrice: $15.02\\nStore: Nirvana   Format: Audio CD\\nCategories: [\\'CDs & Vinyl\\', \\'Pop\\', \\'Adult Alternative\\']\\nUser rating: 4.0\\nUser comment title: 4.25 stars,better than Nevermind, worse than Bleach\\nUser comment: I think I\\'m one of the very few diehards that believes \\'In Utero\\' was not Nirvanas best studio album. Now dont get me wrong, it is far from a bad album, justifying the four star rating, but there are many crudentials lacking of \\'In Utero\\' that aren\\'t as lacking on \\'Bleach\\'. However, some of Nirvanas best and most beautiful songs can be found here; songs like \\'Heart Shaped Box\\', with its depressing lyrics about Kurts heroine addiction and his misfortune that befell him soon after he was hooked, \"forever in debt to your priceless advise\" lets us know that Cobain would much rather have chosen a drug-free path. \\'Rape Me\\' was Kurts anti-Teen Spirit. It is a song about how SLTS \"raped\" Nirvana of their undergroung status and turned them into alternative heroes. \"Rape me my friend\" describes how Kurt almost felt betrayed, because, as most Nirvana fans know, he loved SLTS when he made it, but then after it made him famous its almost as if he despised it. \\'Dumb\\' is a soft ballad and is about the feelings you have when you\\'re high with lyrics like \"I think I\\'m dumb\" and \"We\\'ll float aroung, hang out on clouds\". \\'All Apologies\\' is another ballad, but unlike \\'Dumb\\' it is loud at times. It is a ballad to his wife Courtney Love (who has since ruined Cobains great legacy) and infant daughter Francis Bean, and how he felt like everything that happened to them was his fault. \\'Serve the Servants\\', the opener to the album, is a great rocker that explains the high price of fame. And \\'Very Ape\\' is a bit different, but it has one hell of a catchy riff. As usual Dave Grohl is top knotch, but I do think Novoselic did better on previous albums, I dont know.<br /><br />  The other half of \\'In Utero\\' however, isn\\'t so great. \\'Scentless Apprentice\\' sounds too much like \\'Aneurysm\\', with its its rising riff. \\'Milk It\\' can often times sound pointless, and although the riff is good, it just doesn\\'t make up for what the song lacks. \\'Pennyroyal Tea\\' lacks the insightful lyrics of previous ballads, and although isn\\'t bad, it just doesn\\'t meet my expectations. \\'Tourrettes\\' is just dumb. I know Cobain was originally influenced by punk, but its nothing when compared to other punk driven songs like \\'Territorial Pissings\\' and \\'Aneurysm\\'. \\'Francis Farmer...\\' and \\'Radio Friendly Unit Shifter\\' arent bad, butthey get boring after a while. And also Cobain may sound like he\\'s being coninuously shot in the leg with his banshee screaming. But most of the time he sounds alright.<br /><br />  So, while there may seem to be a lot of things wrong with this, it is overall a 4 star, thanks to classic songs like \\'Heart-shaped Box\\', \\'Rape me\\', and \\'All Apologies\\'. I think any grunge fan should own this, oh, and pick up \\'Bleach\\' too, its Nirvanas best.\\n'}\n",
       "I am a passionate music enthusiast with a particular affinity for grunge and alternative rock, as evidenced by my detailed analysis of Nirvana's \"In Utero.\" My insights reflect a deep appreciation for lyrical depth and the emotional narratives behind the music, while also recognizing the nuances that differentiate albums within an artist's discography. With a solid average rating of 4.8 from over 2,000 users, I understand the diverse perspectives of fellow fans and aim to provide thoughtful critiques that resonate with both diehard followers and casual listeners. My focus is on enhancing user experiences by offering authentic reflections that can guide music choices, making me a valuable resource for anyone seeking to explore or deepen their connection with iconic albums and artists."
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_updated_memory = positive_item.update_backwards(\n",
    "    y_dict[\"y_pred_positive\"],\n",
    "    user_representation=user.user_representation,\n",
    "    explanation=explanation,\n",
    "    y_true=y_dict[\"y_true_positive\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Users passionate about grunge and alternative rock often prioritize albums with lyrical depth and emotional narratives, leading to higher satisfaction with items like 'In Utero'.\n",
      "1: Thoughtful critiques and diverse perspectives significantly influence user preferences, making albums that resonate on a deeper level more appealing.\n",
      "2: Strong average ratings play a crucial role in user decision-making, as they reflect a shared appreciation among fans and can guide future choices.\n",
      "3: Users who enjoy albums with meaningful content tend to rate them positively, reinforcing the value of lyrical insight in music selections.\n",
      "4: When evaluating music, users often compare albums within the same genre, leading to preferences based on critical reception and personal resonance.\n"
     ]
    }
   ],
   "source": [
    "for i, phrase in enumerate(positive_updated_memory):\n",
    "    print(f\"{i}: {phrase}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_update_memory = negative_item.update_backwards(\n",
    "    y_dict[\"y_pred_negative\"],\n",
    "    user_representation=user.user_representation,\n",
    "    explanation=explanation,\n",
    "    y_true=y_dict[\"y_true_negative\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Users who appreciate lyrical depth and emotional narratives may find Green Day's 'Dookie' less appealing compared to grunge-focused albums.\n",
      "1: Strong average ratings significantly influence user decisions, leading them to favor albums with higher perceived quality.\n",
      "2: Thoughtful critiques and diverse perspectives are essential for users seeking meaningful music experiences.\n",
      "3: Users passionate about alternative rock often prefer albums that resonate on a deeper emotional level rather than mainstream pop-punk.\n",
      "4: Mixed opinions about an album can deter users from selecting it, especially if they prioritize critical acclaim.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for i, phrase in enumerate(negative_update_memory):\n",
    "    print(f\"{i}: {phrase}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Evaluation comparasion with sample x no sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# warning level\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def compute_metrics(y_true: List[int], y_pred: List[int]):\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average=\"weighted\")\n",
    "    recall = recall_score(y_true, y_pred, average=\"weighted\")\n",
    "    f1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"mae\": mae,\n",
    "        \"mse\": mse,\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_base_310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
