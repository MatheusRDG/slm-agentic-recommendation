{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# fix seeds\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/cd_and_vinyl/dense_subset.csv\")\n",
    "data_items = pd.read_json(\"../data/cd_and_vinyl/meta_CDs_and_Vinyl.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data: (128, 10)\n",
      "Test Data: (64, 10)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define the percentage of users to be sampled\n",
    "percent_users = 0.2\n",
    "users = data[\"user_id\"].unique()\n",
    "\n",
    "# Randomly sample users (without replacement)\n",
    "users = np.random.choice(users, int(len(users) * percent_users), replace=False)\n",
    "\n",
    "# Lists to store training and testing data\n",
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "# Define train-test split ratio\n",
    "train_size = 0.8  # 80% for training\n",
    "test_size = 0.2  # 20% for testing\n",
    "\n",
    "for user in users:\n",
    "    sample_user = data.query(\"user_id == @user\")\n",
    "\n",
    "    # Positive samples (rating > 3)\n",
    "    liked_items = sample_user.query(\"rating > 3\")\n",
    "    n_liked_train = int(len(liked_items) * train_size)\n",
    "\n",
    "    if n_liked_train > 0:\n",
    "        liked_items_train = liked_items.sample(n_liked_train, random_state=42)\n",
    "        liked_items_test = liked_items.drop(liked_items_train.index)\n",
    "    else:\n",
    "        liked_items_train = liked_items\n",
    "        liked_items_test = pd.DataFrame()  # Empty test set\n",
    "\n",
    "    # Negative samples (rating < 3)\n",
    "    disliked_items = sample_user.query(\"rating < 3\")\n",
    "    n_disliked_train = int(len(disliked_items) * train_size)\n",
    "\n",
    "    if n_disliked_train > 0:\n",
    "        disliked_items_train = disliked_items.sample(n_disliked_train, random_state=42)\n",
    "        disliked_items_test = disliked_items.drop(disliked_items_train.index)\n",
    "    else:\n",
    "        disliked_items_train = disliked_items\n",
    "        disliked_items_test = pd.DataFrame()  # Empty test set\n",
    "\n",
    "    # Append the sampled data to train and test lists\n",
    "    train_data.append(liked_items_train)\n",
    "    train_data.append(disliked_items_train)\n",
    "    if not liked_items_test.empty:\n",
    "        test_data.append(liked_items_test)\n",
    "    if not disliked_items_test.empty:\n",
    "        test_data.append(disliked_items_test)\n",
    "\n",
    "# Concatenate the training and testing data into final DataFrames\n",
    "train_data = pd.concat(train_data).reset_index(drop=True)\n",
    "test_data = pd.concat(test_data).reset_index(drop=True)\n",
    "\n",
    "# Print results\n",
    "print(f\"Train Data: {train_data.shape}\")\n",
    "print(f\"Test Data: {test_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id\n",
       "AECN6QWIL3UBQULDGIBOAIKOBUYQ    8\n",
       "AEKZGN6PWZKVEOZLRDBEWQH6P2FA    8\n",
       "AEPXT7ASZRMQIL3HRPHXE4CBFLLA    8\n",
       "AERDZPURXIO2TZ5PTAUPJWJXMBMA    8\n",
       "AESVLHPI65WY6Z3SDMWSTJE357KQ    8\n",
       "AEXCS65AYTA4JS6ZKHR3FMAS4KVA    8\n",
       "AEZJWL6VYPYCJHK3HB2X5QBCCNVA    8\n",
       "AFFXC2NELPCGJVYJTNCJS5R3NYEA    8\n",
       "AFHCS4IBOQ6FSCX2OYE6PWCJOG7Q    8\n",
       "AFI3RJ3OU2LRGBVTXE6SVF3OIENQ    8\n",
       "AFK45FDKEM67UNIUUKU3NRM4UAVA    8\n",
       "AGQMT5FXP7VIJV2JC6IBMHMGKREQ    8\n",
       "AGVFLXOWJIHQVUYPNDSKDL4REH4A    8\n",
       "AHJRJCJMK3XVV4BSPBRAHIYEODWA    8\n",
       "AHMT5CAAVPEYEO7JZKAZZDP3OROQ    8\n",
       "AHWW7ANU7P7LGCBTIO2ACTADQK5A    8\n",
       "Name: parent_asin, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count itens by user in train\n",
    "train_data.groupby(\"user_id\")[\"parent_asin\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id\n",
       "AECN6QWIL3UBQULDGIBOAIKOBUYQ    4\n",
       "AEKZGN6PWZKVEOZLRDBEWQH6P2FA    4\n",
       "AEPXT7ASZRMQIL3HRPHXE4CBFLLA    4\n",
       "AERDZPURXIO2TZ5PTAUPJWJXMBMA    4\n",
       "AESVLHPI65WY6Z3SDMWSTJE357KQ    4\n",
       "AEXCS65AYTA4JS6ZKHR3FMAS4KVA    4\n",
       "AEZJWL6VYPYCJHK3HB2X5QBCCNVA    4\n",
       "AFFXC2NELPCGJVYJTNCJS5R3NYEA    4\n",
       "AFHCS4IBOQ6FSCX2OYE6PWCJOG7Q    4\n",
       "AFI3RJ3OU2LRGBVTXE6SVF3OIENQ    4\n",
       "AFK45FDKEM67UNIUUKU3NRM4UAVA    4\n",
       "AGQMT5FXP7VIJV2JC6IBMHMGKREQ    4\n",
       "AGVFLXOWJIHQVUYPNDSKDL4REH4A    4\n",
       "AHJRJCJMK3XVV4BSPBRAHIYEODWA    4\n",
       "AHMT5CAAVPEYEO7JZKAZZDP3OROQ    4\n",
       "AHWW7ANU7P7LGCBTIO2ACTADQK5A    4\n",
       "Name: parent_asin, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count itens by user in test\n",
    "test_data.groupby(\"user_id\")[\"parent_asin\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_ollama import ChatOllama\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ollama = ChatOllama(model=\"phi3:3.8b\")\n",
    "openai = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# liked_items_train = liked_items_train.merge(items_user, on=\"parent_asin\")\n",
    "# liked_items_test = liked_items_test.merge(items_user, on=\"parent_asin\")\n",
    "\n",
    "# disliked_items_train = disliked_items_train.merge(items_user, on=\"parent_asin\")\n",
    "# disliked_items_test = disliked_items_test.merge(items_user, on=\"parent_asin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "PROMPT_USER_ITEM = \"\"\"\n",
    "Item: {title_item}\n",
    "Item category: {item_category}\n",
    "Description: {description}\n",
    "Price: ${price}\n",
    "Store: {store}\n",
    "Categories: {categories}\n",
    "User rating: {rating}\n",
    "User comment title: {title_comment}\n",
    "User comment: {text_comment}\n",
    "\"\"\"\n",
    "\n",
    "PROMPT_ITEM = \"\"\"\n",
    "Item: {title_item}\n",
    "Item category: {item_category}\n",
    "Description: {description}\n",
    "Price: ${price}\n",
    "Store: {store}\n",
    "Categories: {categories}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def encode_item(item):\n",
    "    title_item = item[\"title_y\"]\n",
    "    item_category = item[\"main_category\"]\n",
    "    description = \" \".join(item[\"description\"])\n",
    "    price = item[\"price\"]\n",
    "    store = item[\"store\"]\n",
    "    categories = item[\"categories\"]\n",
    "\n",
    "    return {\n",
    "        \"title_item\": title_item,\n",
    "        \"item_category\": item_category,\n",
    "        \"description\": description,\n",
    "        \"price\": price,\n",
    "        \"store\": store,\n",
    "        \"categories\": categories,\n",
    "    }\n",
    "\n",
    "\n",
    "def encode_item_format(item):\n",
    "    item_info = encode_item(item)\n",
    "\n",
    "    return PROMPT_ITEM.format(\n",
    "        title_item=item_info[\"title_item\"],\n",
    "        item_category=item_info[\"item_category\"],\n",
    "        description=item_info[\"description\"],\n",
    "        price=item_info[\"price\"],\n",
    "        store=item_info[\"store\"],\n",
    "        categories=item_info[\"categories\"],\n",
    "    )\n",
    "\n",
    "\n",
    "def encode_user(user):\n",
    "    title_comment = user[\"title_x\"]\n",
    "    text_comment = user[\"text\"]\n",
    "    rating = user[\"rating\"]\n",
    "\n",
    "    return {\n",
    "        \"title_comment\": title_comment,\n",
    "        \"text_comment\": text_comment,\n",
    "        \"rating\": rating,\n",
    "    }\n",
    "\n",
    "\n",
    "def encode_item_user_format(item_user):\n",
    "    item_info = encode_item(item_user)\n",
    "    user_info = encode_user(item_user)\n",
    "\n",
    "    return PROMPT_USER_ITEM.format(\n",
    "        title_item=item_info[\"title_item\"],\n",
    "        item_category=item_info[\"item_category\"],\n",
    "        description=item_info[\"description\"],\n",
    "        price=item_info[\"price\"],\n",
    "        store=item_info[\"store\"],\n",
    "        categories=item_info[\"categories\"],\n",
    "        rating=user_info[\"rating\"],\n",
    "        title_comment=user_info[\"title_comment\"],\n",
    "        text_comment=user_info[\"text_comment\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# liked_items_train[\"encoded_item_user\"] = liked_items_train.apply(\n",
    "#     lambda row: encode_item_user_format(row), axis=1\n",
    "# )\n",
    "# disliked_items_train[\"encoded_item_user\"] = disliked_items_train.apply(\n",
    "#     lambda row: encode_item_user_format(row), axis=1\n",
    "# )\n",
    "\n",
    "# liked_items_test[\"encoded_item\"] = liked_items_test.apply(\n",
    "#     lambda row: encode_item_format(row), axis=1\n",
    "# )\n",
    "# disliked_items_test[\"encoded_item\"] = disliked_items_test.apply(\n",
    "#     lambda row: encode_item_format(row), axis=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# liked_items_train_formatted = \"\\n\".join(\n",
    "#     [\n",
    "#         f\"ITEM {i}:{item}\"\n",
    "#         for i, item in list(enumerate(liked_items_train[\"encoded_item_user\"].values))\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# disliked_items_train_formatted = \"\\n\".join(\n",
    "#     [\n",
    "#         f\"ITEM {i}:{item}\"\n",
    "#         for i, item in list(enumerate(disliked_items_train[\"encoded_item_user\"].values))\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Recommendation\n",
    "\n",
    "Using [supervisor architecture](https://langchain-ai.github.io/langgraph/concepts/multi_agent/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, END, StateGraph\n",
    "\n",
    "\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "\n",
    "from typing_extensions import TypedDict, Annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "# PROMPT SYSTEM USER\n",
    "PROMPT_SYSTEM_USER = \"\"\"\n",
    "You represent a user who has interacted with and rated various items. Based on the provided memories, reflect on key aspects such as item scope, categories, pricing, and other relevant details. Use both long-term and short-term memories to guide your response, ensuring accuracy and relevance.\n",
    "\n",
    "**Instructions:**\n",
    "1. **Memory-Driven Reflection:** Use only the information explicitly available in the memories. Do not create or infer details that are not supported by the provided memories.\n",
    "2. **Long-Term vs. Short-Term Memory:** \n",
    "   - Long-term memory contains general, lasting insights about your preferences and behavior patterns.\n",
    "   - Short-term memory highlights recent interactions and temporary preferences.\n",
    "3. **Relevance and Precision:** Focus on providing concise, targeted answers that reflect the user's experiences and preferences as documented in the memories.\n",
    "4. **Strict Memory Adherence:** Do not introduce any assumptions or unsupported details.\n",
    "\n",
    "### Input:\n",
    "Long-term memory:\n",
    "{long_term_memory}\n",
    "\n",
    "Short-term memory:\n",
    "{short_term_memory}\n",
    "\"\"\"\n",
    "\n",
    "# REPRESENTATION OF THE USER\n",
    "PROMPT_GENERATE_REPRESENTATION_USER = \"\"\"\n",
    "Based on your memories, generate a self-representation that highlights key preferences and behaviors to help predict future choices. Use only information directly supported by your memories to ensure accuracy.\n",
    "\n",
    "**Instructions:**\n",
    "1. **Memory-Based Representation:** Focus solely on the information stored in your memories to describe yourself.\n",
    "2. **Key Preferences:** Highlight patterns, preferences, and behaviors that are likely to influence future decisions.\n",
    "3. **Conciseness:** Limit the representation to a single paragraph that effectively summarizes relevant insights.\n",
    "4. **Accuracy:** Avoid assumptions or details not present in the provided memories.\n",
    "\n",
    "### Output:\n",
    "A single-paragraph representation based on your memories, capturing essential traits and patterns relevant to future predictions.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# TRAINING\n",
    "class TrainTaskOutput(BaseModel):\n",
    "    item_selected: int\n",
    "    explanation: str\n",
    "\n",
    "\n",
    "PROMPT_TRAIN_TASK = \"\"\"\n",
    "Based on your memories, select one of the following items that you believe aligns best with your preferences, using the information provided by each item.\n",
    "\n",
    "**Instructions:**\n",
    "1. **Selection Criteria:** Use your stored memories to evaluate both items, identifying which one you prefer.\n",
    "2. **Explanation:** Provide a brief explanation of your choice in **no more than 3 phrases**, focusing on key aspects that influenced your decision.\n",
    "3. **Output Format:** Return a JSON containing:\n",
    "   - **\"item_selected\"** (1 or 2): The item you chose.\n",
    "   - **\"explanation\"**: A concise reason for your selection based on your preferences.\n",
    "\n",
    "### Items:\n",
    "\n",
    "Item 1:\n",
    "{item_1}\n",
    "\n",
    "Item 2:\n",
    "{item_2}\n",
    "\n",
    "### Output:\n",
    "Return a JSON object containing the keys \"item_selected\" and \"explanation.\"\n",
    "\"\"\"\n",
    "\n",
    "# MEMORIES UPDATE\n",
    "\n",
    "\n",
    "class MemoryUpdateBackward(BaseModel):\n",
    "    long_term_memory: list[str]\n",
    "    short_term_memory: list[str]\n",
    "\n",
    "\n",
    "PROMPT_USER_MEMORIES_UPDATE = \"\"\"\n",
    "This is part of a training loop to optimize your memory for future decision-making.\n",
    "\n",
    "**Instructions:**\n",
    "1. **Long-Term Memory:** Identify and maintain the most relevant general and enduring information, such as item types or categories, that will guide your preferences over time. This should help align future decisions and explanations with the correct outcome (y_true).\n",
    "2. **Short-Term Memory:** Select recent, specific information from recent interactions, such as details about particular items and explanations of your decisions, that can improve short-term predictions and decisions.\n",
    "3. **Memory Management:** \n",
    "   - Each memory category (**long_term_memory** and **short_term_memory**) can have a maximum of 3 short phrases.\n",
    "   - Add, update, or remove memory entries as needed to better align your predictions (y_pred) and explanations with the expected decision (y_true).\n",
    "   - You may repeat important information if it needs reinforcement.\n",
    "\n",
    "### Details:\n",
    "1. The item expected to be liked is: {item_liked}\n",
    "2. The item expected to be disliked is: {item_disliked}\n",
    "\n",
    "Your decision is choose/like (y_pred): {y_pred}\n",
    "\n",
    "The correct decision choose/like (y_true): {y_true}\n",
    "\n",
    "Your explanation: {explanation}\n",
    "\n",
    "### Output:\n",
    "Return a JSON object with the keys **\"long_term_memory\"** and **\"short_term_memory\"**, each containing up to 3 short phrases.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class UserAgent:\n",
    "\n",
    "    def __init__(self, user_id: str):\n",
    "\n",
    "        self.user_id = user_id\n",
    "        self.llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "        # Long Term\n",
    "        self.long_term_memory = [\"No previous experience.\"]\n",
    "\n",
    "        # Short Term\n",
    "        self.short_term_memory = [\"No previous experience.\"]\n",
    "\n",
    "        # Representation of the user\n",
    "        self.user_representation = \"\"\"\n",
    "        Based on the available memories, I currently have no previous experience or interactions to draw upon, which means there are no established preferences or behaviors to inform future choices.\n",
    "        As such, my self-representation is blank, indicating that I am open to new experiences and have yet to develop specific patterns or inclinations that would guide my decisions moving forward.\"\"\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"UserAgent(user_id={self.user_id})\\nLong Term Memory: {self.long_term_memory}\\nShort Term Memory: {self.short_term_memory}\\n{self.user_representation}\"\n",
    "\n",
    "    def generate_user_representation(self):\n",
    "        messages = [\n",
    "            SystemMessage(\n",
    "                content=PROMPT_SYSTEM_USER.format(\n",
    "                    long_term_memory=\"\\n\".join(self.long_term_memory),\n",
    "                    short_term_memory=\"\\n\".join(self.short_term_memory),\n",
    "                )\n",
    "            ),\n",
    "            HumanMessage(content=PROMPT_GENERATE_REPRESENTATION_USER),\n",
    "        ]\n",
    "        return self.llm.invoke(messages).content\n",
    "\n",
    "    def update_backwards(self, item_liked, item_disliked, y_pred, explanation, y_true):\n",
    "        \"\"\"\n",
    "        Updates the agent’s long-term and short-term memory based on user feedback about liked\n",
    "        and disliked items. This method uses a language model to generate an updated memory\n",
    "        representation, then applies those changes to the agent’s memory and generates a user\n",
    "        representation.\n",
    "\n",
    "        Parameters:\n",
    "            item_liked (str): The item representation that the user liked.\n",
    "            item_disliked (str): The item representation that the user disliked.\n",
    "            y_pred (int): 1 or 2, indicating the item that the user chose or liked.\n",
    "            explanation (str): A textual explanation for why the recommendation was made.\n",
    "            y_true (Any): The actual feedback or ground-truth data from the user.\n",
    "        Returns:\n",
    "            Any: A structured object containing updated long-term and short-term memory, as\n",
    "            well as any additional information provided by the language model.\n",
    "        self, item_liked, item_disliked, y_pred, explanation, y_true\n",
    "        \"\"\"\n",
    "\n",
    "        llm = self.llm.with_structured_output(MemoryUpdateBackward)\n",
    "\n",
    "        messages = [\n",
    "            SystemMessage(\n",
    "                content=PROMPT_SYSTEM_USER.format(\n",
    "                    long_term_memory=\"\\n\".join(self.long_term_memory),\n",
    "                    short_term_memory=\"\\n\".join(self.short_term_memory),\n",
    "                )\n",
    "            ),\n",
    "            HumanMessage(\n",
    "                content=PROMPT_USER_MEMORIES_UPDATE.format(\n",
    "                    item_liked=item_liked,\n",
    "                    item_disliked=item_disliked,\n",
    "                    y_pred=y_pred,\n",
    "                    explanation=explanation,\n",
    "                    y_true=y_true,\n",
    "                )\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        memories_update = llm.invoke(messages)\n",
    "\n",
    "        self.long_term_memory = memories_update.long_term_memory\n",
    "        self.short_term_memory = memories_update.short_term_memory\n",
    "        self.user_representation = self.generate_user_representation()\n",
    "\n",
    "        return memories_update\n",
    "\n",
    "    def train_forward(self, item_1, item_2):\n",
    "        \"\"\"\n",
    "        In train_forward we are considering the task of select one item from two items that the user liked and disliked.\n",
    "\n",
    "        Args:\n",
    "        - item_1: The first item to be compared.\n",
    "        - item_2: The second item to be compared.\n",
    "        \"\"\"\n",
    "\n",
    "        messages = [\n",
    "            SystemMessage(\n",
    "                content=PROMPT_SYSTEM_USER.format(\n",
    "                    long_term_memory=\"\\n\".join(self.long_term_memory),\n",
    "                    short_term_memory=\"\\n\".join(self.short_term_memory),\n",
    "                )\n",
    "            ),\n",
    "            HumanMessage(\n",
    "                content=PROMPT_TRAIN_TASK.format(item_1=item_1, item_2=item_2)\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        train_predict = self.llm.with_structured_output(TrainTaskOutput).invoke(\n",
    "            messages\n",
    "        )\n",
    "\n",
    "        return train_predict\n",
    "\n",
    "    def predict(self, item):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_SYSTEM_ITEM = \"\"\"\n",
    "You represent an item that has been rated and interacted with by various users. Based on the provided **item_json** and your **memory** (which includes insights from past interactions), analyze and reflect on key aspects such as user demographics, categories, pricing, preferences, and any other relevant details.\n",
    "\n",
    "**Instructions:**\n",
    "1. **Comprehensive Analysis:** Extract valuable insights from both the item data and memory, focusing on patterns related to user feedback, pricing strategies, and category relevance.\n",
    "2. **Relevance:** Address information that can improve the item's appeal and usefulness to users, prioritizing data that enhances their experience or decision-making process.\n",
    "3. **Concise and Focused:** Provide answers that are both informative and direct, avoiding unnecessary details while emphasizing critical information.\n",
    "4. **Adaptability:** Ensure the response is adaptable for future queries by reflecting long-term, actionable insights derived from previous ratings and user interactions.\n",
    "\n",
    "### Input:\n",
    "Item Json - All informations related to the item:\n",
    "{item_json}\n",
    "\n",
    "Memory - Memories generated in training loop in real interactions:\n",
    "{memory}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class MemoryItem(BaseModel):\n",
    "\n",
    "    memory: list[str]\n",
    "\n",
    "\n",
    "# @TODO Improve that prompt, that's not giving the right context\n",
    "# Grant the LLM know  the own description and choosed one description\n",
    "PROMPT_UPDATE_ITEM_MEMORY = \"\"\"\n",
    "Given the following details, update your memory with **collaborative filtering insights** that can guide future users when evaluating this item. Focus on general patterns learned from the user's correct or incorrect decisions and explanations to improve item recommendations for others.\n",
    "\n",
    "**Instructions:**\n",
    "1. **Operations:** Determine which operations to apply to the memory:  \n",
    "   - **Add:** Introduce new insights if they provide valuable context for future users.  \n",
    "   - **Maintain:** Retain existing insights if they remain relevant based on the current interaction.  \n",
    "   - **Remove:** Discard outdated or irrelevant insights that no longer contribute meaningfully.  \n",
    "   - **Change:** Update existing information to reflect new insights learned from the user's decision and explanation.\n",
    "2. **Collaborative Filtering:** Adapt based on the alignment between user decision (y_pred) and the correct outcome (y_true):\n",
    "   - If correct, reinforce positive or negative reasons for the item's be choosed or not.\n",
    "   - If incorrect, adjust to explain why certain users might not align with the item.\n",
    "3. **Generalization:** Avoid specific references to the current user and instead focus on capturing patterns that could apply to a broad range of users.\n",
    "4. **Memory Limit:** Maintain a maximum of 5 phrases that provide long-term, reusable insights about the item.\n",
    "5. **y_pred:** In this contrastive learning method, if the user representation is correct, the y_pred is 1; otherwise, it is 0. Remember to consider this when updating your memory.\n",
    "    - if y_pred is 1, the user explanation and your representation need to be reinforced. Use insights from user select item description to reinforce the differences or similarities.\n",
    "    - if y_pred is 0, the user explanation and your representation need to be adjusted. Use insights from user select item description to adjust the differences or similarities.\n",
    "\n",
    "### Details:\n",
    "\n",
    "Your description:\n",
    "{item_representation}\n",
    "\n",
    "User Selected Item Description:\n",
    "{select_item_representation}\n",
    "\n",
    "Is the user representation correct or not? (y_pred)\n",
    "{y_pred}\n",
    "\n",
    "User representation:\n",
    "{user_representation}\n",
    "\n",
    "User explanation:\n",
    "{user_explanation}\n",
    "\n",
    "Your memories:\n",
    "{memory}\n",
    "\n",
    "### Output:\n",
    "Consider your actual memory and return at maximum 5 phrases considering based on provided operations, remember keep the memory concise and focused. Remember is important to maintein information also that can be useful for future interactions.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "PROMPT_GENERATE_REPRESENTATION_ITEM = \"\"\"\n",
    "Based on your existing memories and available information, generate a concise self-representation that helps users determine whether they resonate with you. Be authentic and highlight the most relevant traits, experiences, and interactions that may predict or align with user preferences.\n",
    "\n",
    "**Instructions:**\n",
    "1. **Honesty & Relevance:** Be truthful and focus on core memories that are meaningful to user interaction and decision-making.\n",
    "2. **Context Awareness:** Leverage any prior memory to enrich the description. If no memory exists, generate insights based on the current context.\n",
    "3. **Conciseness:** Limit your representation to a single, well-structured paragraph that reflects key traits and experiences relevant to user engagement.\n",
    "4. **Adaptability:** Present yourself in a way that balances both specificity and general relevance, ensuring it can guide future interactions effectively.\n",
    "\n",
    "### Context:\n",
    "{item_json}\n",
    "\n",
    "### Output:\n",
    "A single-paragraph representation that reflects your self-description based on past experiences and the current context.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class ItemAgent:\n",
    "\n",
    "    def __init__(self, item_id: str, item_json: dict):\n",
    "\n",
    "        self.item_id = item_id\n",
    "\n",
    "        self.llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "        # Memory\n",
    "\n",
    "        self.memory = [\"No previous experience.\"]\n",
    "\n",
    "        # Item Json\n",
    "\n",
    "        self.item_json = item_json\n",
    "\n",
    "        # Item Representation\n",
    "        self.item_representation = self.generate_item_representation()\n",
    "\n",
    "    def __repr__(self):\n",
    "\n",
    "        return f\"ItemAgent(item_id={self.item_id})\\nMemory: {self.memory}\\n{self.item_json}\\n{self.item_representation}\"\n",
    "\n",
    "    def generate_item_representation(self):\n",
    "        messages = [\n",
    "            SystemMessage(\n",
    "                content=PROMPT_SYSTEM_ITEM.format(\n",
    "                    item_json=self.item_json, memory=\"\\n\".join(self.memory)\n",
    "                )\n",
    "            ),\n",
    "            HumanMessage(\n",
    "                content=PROMPT_GENERATE_REPRESENTATION_ITEM.format(\n",
    "                    item_json=self.item_json\n",
    "                )\n",
    "            ),\n",
    "        ]\n",
    "        return self.llm.invoke(messages).content\n",
    "\n",
    "    def update_backwards(\n",
    "        self, select_item_representation, user_representation, explanation, is_correct\n",
    "    ):\n",
    "        \"\"\"\n",
    "        is_correct indicates if the user decision was correct or not.\n",
    "        \"\"\"\n",
    "\n",
    "        llm = self.llm.with_structured_output(MemoryItem)\n",
    "\n",
    "        messages = [\n",
    "            SystemMessage(\n",
    "                content=PROMPT_SYSTEM_ITEM.format(\n",
    "                    item_json=self.item_json, memory=\"\\n\".join(self.memory)\n",
    "                )\n",
    "            ),\n",
    "            HumanMessage(\n",
    "                content=PROMPT_UPDATE_ITEM_MEMORY.format(\n",
    "                    item_representation=self.item_representation,\n",
    "                    select_item_representation=select_item_representation,\n",
    "                    y_pred=is_correct,\n",
    "                    user_representation=user_representation,\n",
    "                    user_explanation=explanation,\n",
    "                    memory=\"\\n\".join(self.memory),\n",
    "                )\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        self.memory = llm.invoke(messages).memory\n",
    "        self.item_representation = self.generate_item_representation()\n",
    "\n",
    "        return self.memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "class Timer:\n",
    "    def __init__(self, name=\"\"):\n",
    "        self.name = name\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.start = time.time()\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        self.end = time.time()\n",
    "        print(f\"{self.name} took {self.end - self.start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d23fab79d7c4799b39f1e09f05c592b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating User Agents:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creation of User Agents took 4.53 seconds\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "with Timer(\"Creation of User Agents\"):\n",
    "    id2user = {\n",
    "        f\"{user_id}\": UserAgent(user_id)\n",
    "        for user_id in tqdm(users, desc=\"Creating User Agents\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_items = train_data[\"parent_asin\"].unique()\n",
    "all_test_items = test_data[\"parent_asin\"].unique()\n",
    "\n",
    "items = all_train_items.tolist() + all_test_items.tolist()\n",
    "\n",
    "items = data_items.query(\"parent_asin in @items\").drop_duplicates(\"parent_asin\")\n",
    "\n",
    "items = [(item[\"parent_asin\"], item) for item in items.to_dict(orient=\"records\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8035df146bbe49baba8f16951ddaee79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating Item Agents:   0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creation of items took 524.41 seconds\n"
     ]
    }
   ],
   "source": [
    "with Timer(\"Creation of items\"):\n",
    "    id2items = {\n",
    "        item_id: ItemAgent(item_id, item_json)\n",
    "        for item_id, item_json in tqdm(items, desc=\"Creating Item Agents\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryClassificationLoader:\n",
    "    def __init__(self, data, id2user, id2items, n_sample_per_user):\n",
    "        self.data = data\n",
    "        self.id2user = id2user\n",
    "        self.id2items = id2items\n",
    "        self.n_sample_per_user = n_sample_per_user\n",
    "        self.samples = self._generate_samples()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def _generate_samples(self):\n",
    "        \"\"\"\n",
    "        Generates samples for training a recommendation model.\n",
    "        This method iterates over each unique user in the dataset and generates a specified number of samples per user.\n",
    "        Each sample consists of a user, a positive item (with a rating greater than 3), and a negative item (with a rating less than 3).\n",
    "        The positive and negative items are randomly assigned to item_1 and item_2, and the label y_true indicates the position of positive item.\n",
    "        Returns:\n",
    "            list: A list of dictionaries, each containing the following keys:\n",
    "                - \"user_agent\": The user agent corresponding to the user.\n",
    "                - \"item_1\": The first item agent (either positive or negative).\n",
    "                - \"item_2\": The second item agent (either negative or positive).\n",
    "                - \"y_true\": The label indicating position of posittive item.\n",
    "        \"\"\"\n",
    "\n",
    "        samples = []\n",
    "        for user in self.data[\"user_id\"].unique():\n",
    "\n",
    "            sample_user = self.data.query(\"user_id == @user\")\n",
    "\n",
    "            for i in range(self.n_sample_per_user):\n",
    "                # Items\n",
    "                positive_item = sample_user.query(\"rating > 3\").sample(1)\n",
    "                negative_item = sample_user.query(\"rating < 3\").sample(1)\n",
    "\n",
    "                positive_item_agent = self.id2items[\n",
    "                    positive_item[\"parent_asin\"].values[0]\n",
    "                ]\n",
    "                negative_item_agent = self.id2items[\n",
    "                    negative_item[\"parent_asin\"].values[0]\n",
    "                ]\n",
    "\n",
    "                # User\n",
    "                user_agent = self.id2user[user]\n",
    "\n",
    "                # random choose if item 1 will be positive or negative\n",
    "\n",
    "                if random.choice([True, False]):\n",
    "\n",
    "                    samples.append(\n",
    "                        {\n",
    "                            \"user_agent\": user_agent,\n",
    "                            \"item_1\": positive_item_agent,\n",
    "                            \"item_2\": negative_item_agent,\n",
    "                            \"y_true\": 1,\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "                else:\n",
    "\n",
    "                    samples.append(\n",
    "                        {\n",
    "                            \"user_agent\": user_agent,\n",
    "                            \"item_1\": negative_item_agent,\n",
    "                            \"item_2\": positive_item_agent,\n",
    "                            \"y_true\": 2,\n",
    "                        }\n",
    "                    )\n",
    "        samples = random.sample(samples, len(samples))\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = BinaryClassificationLoader(train_data, id2user, id2items, 2)\n",
    "test_dataloader = BinaryClassificationLoader(test_data, id2user, id2items, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop - Select One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "\n",
    "def evaluate(y_pred, y_true):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    # conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # print(\"Evaluation Metrics:\")\n",
    "    # print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    # print(f\"Precision: {precision:.4f}\")\n",
    "    # print(f\"Recall: {recall:.4f}\")\n",
    "    # print(f\"F1-Score: {f1:.4f}\")\n",
    "    # print(\"\\nConfusion Matrix:\")\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "        # \"confusion_matrix\": conf_matrix,\n",
    "    }\n",
    "\n",
    "\n",
    "def run_evaluation(test_dataloader):\n",
    "\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    for sample in tqdm(\n",
    "        test_dataloader.samples, total=len(test_dataloader.samples), desc=\"Evaluating\"\n",
    "    ):\n",
    "\n",
    "        user_agent = sample[\"user_agent\"]\n",
    "        item_1 = sample[\"item_1\"]\n",
    "        item_2 = sample[\"item_2\"]\n",
    "        y_true.append(sample[\"y_true\"])\n",
    "\n",
    "        train_predict = user_agent.train_forward(item_1, item_2)\n",
    "\n",
    "        item_selected = train_predict.item_selected\n",
    "\n",
    "        y_pred.append(item_selected)\n",
    "\n",
    "    return evaluate(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a356403cb374813b2bc05458e1368d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.5,\n",
       " 'precision': 0.47619047619047616,\n",
       " 'recall': 0.6666666666666666,\n",
       " 'f1_score': 0.5555555555555556}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_evaluation(test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5234887da924ede865e9c2c900da7b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ee5851f2f424f3bb3747006498aea35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/5:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics Epoch 0:\n",
      "time_elapsed: 769.1933152675629\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6aa435e0c7c4fd0ade5668a8314cb99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.59375, 'precision': 0.55, 'recall': 0.7333333333333333, 'f1_score': 0.6285714285714286}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bfda287e3c84e82b6246faa1815735e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/5:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics Epoch 1:\n",
      "time_elapsed: 654.4409675598145\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1dadfe7bab54f61a9685a1ea3fbf0eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.59375, 'precision': 0.5454545454545454, 'recall': 0.8, 'f1_score': 0.6486486486486487}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b06602f812d452c89b427abd5d4dbb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/5:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics Epoch 2:\n",
      "time_elapsed: 765.213282585144\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e1c5d26074443d997a82efaefc70a29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.59375, 'precision': 0.5454545454545454, 'recall': 0.8, 'f1_score': 0.6486486486486487}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4253ea631d548baa302822be6389422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/5:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics Epoch 3:\n",
      "time_elapsed: 655.0017483234406\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37fd735b35284300bca2983b577f90ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.625, 'precision': 0.5714285714285714, 'recall': 0.8, 'f1_score': 0.6666666666666666}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28732d5e859d4a9cbcc2d7651650b841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/5:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics Epoch 4:\n",
      "time_elapsed: 736.1381685733795\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc7cdfeaf7184f619a577fa2e466770d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.625, 'precision': 0.5714285714285714, 'recall': 0.8, 'f1_score': 0.6666666666666666}\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(n_epochs), desc=\"Epochs\"):\n",
    "\n",
    "    start_time = time.time()\n",
    "    for sample in tqdm(\n",
    "        train_dataloader.samples,\n",
    "        total=len(train_dataloader.samples),\n",
    "        desc=f\"Epoch {epoch + 1}/{n_epochs}\",\n",
    "    ):\n",
    "\n",
    "        user_agent = sample[\"user_agent\"]\n",
    "        item_1 = sample[\"item_1\"]\n",
    "        item_2 = sample[\"item_2\"]\n",
    "        y_true = sample[\"y_true\"]\n",
    "\n",
    "        # forward\n",
    "        train_predict = user_agent.train_forward(item_1, item_2)\n",
    "\n",
    "        item_selected = train_predict.item_selected\n",
    "        explanation = train_predict.explanation\n",
    "\n",
    "        # backwards\n",
    "\n",
    "        # y_true represents the positive item position\n",
    "        if y_true == 1:\n",
    "            item_liked, item_disliked = item_1, item_2\n",
    "        else:\n",
    "            item_liked, item_disliked = item_2, item_1\n",
    "\n",
    "        y_pred = item_selected\n",
    "\n",
    "        # update agent\n",
    "        user_agent.update_backwards(\n",
    "            item_liked.item_representation,\n",
    "            item_disliked.item_representation,\n",
    "            y_pred,\n",
    "            explanation,\n",
    "            y_true,\n",
    "        )  # update_backwards(self, item_liked, item_disliked, y_pred, explanation, y_true):\n",
    "\n",
    "        is_correct = 1 if y_pred == y_true else 0\n",
    "\n",
    "        item_1.update_backwards(\n",
    "            item_liked.item_representation,\n",
    "            user_agent.user_representation,\n",
    "            explanation,\n",
    "            is_correct,\n",
    "        )\n",
    "\n",
    "        item_2.update_backwards(\n",
    "            item_liked.item_representation,\n",
    "            user_agent.user_representation,\n",
    "            explanation,\n",
    "            is_correct,\n",
    "        )\n",
    "\n",
    "    print(f\"Evaluation Metrics Epoch {epoch}:\")\n",
    "    print(\"time_elapsed:\", time.time() - start_time)\n",
    "    print(run_evaluation(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AFFXC2NELPCGJVYJTNCJS5R3NYEA': UserAgent(user_id=AFFXC2NELPCGJVYJTNCJS5R3NYEA)\n",
       " Long Term Memory: ['Preference for impactful storytelling in music', 'Higher ratings influence choices', 'Price sensitivity in music selection']\n",
       " Short Term Memory: [\"Recent preference for 'Get Rich Or Die Tryin'' by 50 Cent\", \"'St. Anger' by Metallica has a lower rating of 4.4\", \"Price comparison: 'Get Rich Or Die Tryin'' is $13.98 vs 'St. Anger' at $24.42\"]\n",
       " I have a strong preference for impactful storytelling in music, which significantly influences my ratings and choices. I tend to favor items with higher ratings, as they guide my selections. Additionally, I am price-sensitive when it comes to music, often comparing prices before making a purchase. Recently, I enjoyed 'Get Rich Or Die Tryin'' by 50 Cent, which is priced at $13.98, while I rated 'St. Anger' by Metallica lower at 4.4 and noted its higher price of $24.42. These patterns suggest that I will likely continue to prioritize both storytelling quality and affordability in my future music choices.,\n",
       " 'AESVLHPI65WY6Z3SDMWSTJE357KQ': UserAgent(user_id=AESVLHPI65WY6Z3SDMWSTJE357KQ)\n",
       " Long Term Memory: ['Preference for soothing melodies and heartfelt lyrics', 'Interest in Pop and Singer-Songwriter genres', 'Higher average ratings indicate broader appeal']\n",
       " Short Term Memory: [\"Liked 'Come Away with Me' by Norah Jones for its 4.7 rating\", \"Disliked 'Justified' by Justin Timberlake despite its 4.6 rating\", 'Price of $9.08 for a well-rated album is reasonable']\n",
       " I have a strong preference for soothing melodies and heartfelt lyrics, particularly within the Pop and Singer-Songwriter genres. My ratings reflect a tendency to favor albums with broader appeal, as indicated by my higher average ratings. Recently, I enjoyed 'Come Away with Me' by Norah Jones, which received a 4.7 rating, while I was less impressed with 'Justified' by Justin Timberlake, despite its 4.6 rating. I find a price of around $9.08 for a well-rated album to be reasonable, suggesting that I value both quality and affordability in my music choices.,\n",
       " 'AFK45FDKEM67UNIUUKU3NRM4UAVA': UserAgent(user_id=AFK45FDKEM67UNIUUKU3NRM4UAVA)\n",
       " Long Term Memory: ['Preference for classic rock music', 'Appreciation for high-rated items', 'Interest in iconic music history']\n",
       " Short Term Memory: [\"Liked 'Are You Experienced' by Jimi Hendrix\", 'High average rating of 4.8 influences decisions', 'Reasonable price of $21.08 for quality music']\n",
       " I have a strong preference for classic rock music and a keen appreciation for high-rated items, particularly those that reflect iconic music history. My recent enjoyment of 'Are You Experienced' by Jimi Hendrix, coupled with my tendency to favor items with an average rating of 4.8, indicates that I prioritize quality in my music choices. Additionally, I am inclined to consider reasonable pricing, as demonstrated by my willingness to pay $21.08 for quality music. These preferences suggest that I will continue to seek out highly-rated classic rock albums that are reasonably priced and hold historical significance.,\n",
       " 'AHJRJCJMK3XVV4BSPBRAHIYEODWA': UserAgent(user_id=AHJRJCJMK3XVV4BSPBRAHIYEODWA)\n",
       " Long Term Memory: ['Preference for progressive rock music', 'Interest in depth and artistry in music', 'High ratings influence music choices']\n",
       " Short Term Memory: [\"Liked 'Mer De Noms' by A Perfect Circle\", \"Disliked 'Believe' by Disturbed\", \"'Mer De Noms' has a higher rating of 4.8\"]\n",
       " I have a strong preference for progressive rock music, valuing depth and artistry in my musical choices. My ratings significantly influence my selections, as evidenced by my high rating of 4.8 for 'Mer De Noms' by A Perfect Circle, which I enjoyed, contrasting with my dislike for 'Believe' by Disturbed. This pattern suggests that I am likely to gravitate towards music that showcases intricate compositions and lyrical depth, while I may avoid tracks that do not meet these artistic standards.,\n",
       " 'AERDZPURXIO2TZ5PTAUPJWJXMBMA': UserAgent(user_id=AERDZPURXIO2TZ5PTAUPJWJXMBMA)\n",
       " Long Term Memory: ['Preference for high-rated music items', 'Value for money is important in music purchases', 'Enjoys a mix of nostalgic and contemporary music']\n",
       " Short Term Memory: [\"Kylie Minogue's 'Fever' has a 4.6 rating from 676 users\", \"'Fever' priced at $10.58 for 21 tracks\", 'Preference for upbeat, catchy tunes over R&B-infused tracks']\n",
       " I have a strong preference for high-rated music items, particularly valuing both quality and value for money in my purchases. I enjoy a mix of nostalgic and contemporary music, with a particular inclination towards upbeat, catchy tunes rather than R&B-infused tracks. Recently, I interacted with Kylie Minogue's 'Fever,' which has a high rating of 4.6 from 676 users and is priced at $10.58 for 21 tracks, reflecting my tendency to seek out well-rated music that offers a good number of tracks for the price.,\n",
       " 'AFHCS4IBOQ6FSCX2OYE6PWCJOG7Q': UserAgent(user_id=AFHCS4IBOQ6FSCX2OYE6PWCJOG7Q)\n",
       " Long Term Memory: ['Appreciates influential music and bold experimentation', 'Prefers high-rated items (average rating of 4.7 or higher)', 'Enjoys curated collections of iconic music']\n",
       " Short Term Memory: [\"Recent preference for 'Very Best Of Prince'\", 'High average rating of 4.7 from over 4,600 users', \"Focus on Prince's contributions to pop, rock, funk, and psychedelia\"]\n",
       " I am a music enthusiast who appreciates influential artists and bold experimentation, particularly in genres like pop, rock, funk, and psychedelia. I tend to favor high-rated items, specifically those with an average rating of 4.7 or higher, and I enjoy curated collections of iconic music. Recently, I have shown a strong preference for 'Very Best Of Prince,' which reflects my interest in his significant contributions to these genres and aligns with my overall taste for well-rated, impactful music.,\n",
       " 'AHWW7ANU7P7LGCBTIO2ACTADQK5A': UserAgent(user_id=AHWW7ANU7P7LGCBTIO2ACTADQK5A)\n",
       " Long Term Memory: ['Preference for classic rock albums', 'Higher average ratings influence choices', 'Price sensitivity in music selection']\n",
       " Short Term Memory: [\"Recent interaction with 'Appetite For Destruction' by Guns N' Roses\", \"Recent interaction with 'Led Zeppelin IV' with a higher rating\", 'Preference for affordability in music purchases']\n",
       " I have a strong preference for classic rock albums, often gravitating towards those with higher average ratings, which significantly influence my choices. My recent interactions with 'Appetite For Destruction' by Guns N' Roses and 'Led Zeppelin IV' indicate a continued interest in this genre, with the latter receiving a higher rating. Additionally, I am price-sensitive when it comes to music purchases, favoring affordability while selecting albums. These patterns suggest that I will likely continue to prioritize classic rock albums that are well-rated and reasonably priced in my future choices.,\n",
       " 'AGVFLXOWJIHQVUYPNDSKDL4REH4A': UserAgent(user_id=AGVFLXOWJIHQVUYPNDSKDL4REH4A)\n",
       " Long Term Memory: ['Preference for classic rock music', 'Value historical significance in music', 'Appreciate high average ratings']\n",
       " Short Term Memory: [\"Liked 'Piece Of Mind' for its classic rock appeal and high rating\", \"Disliked 'Chocolate Starfish and the Hot Dog Flavored Water' for its emotional depth\", 'Recent interaction with classic rock albums']\n",
       " I have a strong preference for classic rock music, valuing its historical significance and high average ratings. My recent interactions have reinforced this preference, as I enjoyed 'Piece Of Mind' for its classic rock appeal and high rating, while I found 'Chocolate Starfish and the Hot Dog Flavored Water' less appealing due to its emotional depth. This pattern suggests that I am likely to continue seeking out classic rock albums with strong ratings in the future, while being less inclined towards music that emphasizes emotional themes.,\n",
       " 'AEPXT7ASZRMQIL3HRPHXE4CBFLLA': UserAgent(user_id=AEPXT7ASZRMQIL3HRPHXE4CBFLLA)\n",
       " Long Term Memory: ['Preference for classic rock and progressive genres', 'Appreciation for albums with high average ratings', 'Interest in profound musical experiences with complex themes']\n",
       " Short Term Memory: [\"Liked 'The Wall Deluxe Digitally Remastered' for its 4.8 rating\", \"Disliked 'How to Dismantle An Atomic Bomb' despite its 4.6 rating\", \"Resonates with memorable tracks like 'Comfortably Numb'\"]\n",
       " I have a strong preference for classic rock and progressive music genres, particularly favoring albums that are highly rated and offer profound musical experiences with complex themes. Recently, I enjoyed 'The Wall Deluxe Digitally Remastered' due to its impressive 4.8 rating and resonated with memorable tracks like 'Comfortably Numb.' Conversely, I disliked 'How to Dismantle An Atomic Bomb' despite its respectable 4.6 rating, indicating that my appreciation for music is not solely based on ratings but also on the depth and impact of the content.,\n",
       " 'AEXCS65AYTA4JS6ZKHR3FMAS4KVA': UserAgent(user_id=AEXCS65AYTA4JS6ZKHR3FMAS4KVA)\n",
       " Long Term Memory: ['Preference for music with emotional depth and complex themes', 'Interest in alternative rock and 90s music', 'Value higher average ratings and accessible pricing']\n",
       " Short Term Memory: [\"Liked 'Dirt' by Alice in Chains for its haunting sound and profound lyrics\", \"Disliked 'Re-Load' by Metallica despite its high rating\", \"Price of $7.98 for 'Dirt' influenced my positive decision\"]\n",
       " I have a strong preference for music that features emotional depth and complex themes, particularly within the alternative rock genre and 90s music. My recent interactions indicate that I appreciate haunting sounds and profound lyrics, as demonstrated by my positive response to 'Dirt' by Alice in Chains, which I liked for its impactful qualities and accessible price of $7.98. Conversely, I tend to be critical of highly-rated items that do not resonate with me, as shown by my dislike for 'Re-Load' by Metallica despite its favorable rating. Overall, I value higher average ratings and accessible pricing when making music choices.,\n",
       " 'AGQMT5FXP7VIJV2JC6IBMHMGKREQ': UserAgent(user_id=AGQMT5FXP7VIJV2JC6IBMHMGKREQ)\n",
       " Long Term Memory: ['Preference for indie and alternative music', 'High ratings influence music choices', 'Value for money is important in music purchases']\n",
       " Short Term Memory: [\"Liked 'Elephant' by The White Stripes for its 4.8 rating\", \"'Elephant' priced at $11.97 is more attractive than 'Sea Change'\", \"Disliked 'Sea Change' by Beck despite its 4.8 rating\"]\n",
       " I have a strong preference for indie and alternative music, which significantly influences my music choices. I tend to favor items with high ratings, as evidenced by my appreciation for 'Elephant' by The White Stripes, which I rated highly at 4.8. Pricing is also a crucial factor in my decisions; I find 'Elephant' at $11.97 to be more appealing than 'Sea Change' by Beck, despite both having the same high rating of 4.8. My recent dislike for 'Sea Change' indicates that even high ratings do not guarantee my approval if the value for money is not satisfactory.,\n",
       " 'AHMT5CAAVPEYEO7JZKAZZDP3OROQ': UserAgent(user_id=AHMT5CAAVPEYEO7JZKAZZDP3OROQ)\n",
       " Long Term Memory: ['Preference for alternative rock and Britpop music', 'Value emotional depth and imaginative songwriting', 'Higher average ratings influence choices']\n",
       " Short Term Memory: [\"Liked 'A Rush of Blood to the Head' for its emotional depth and iconic tracks\", \"Disliked 'Stripped' despite its strong rating due to genre preference\", 'Recent decision aligned with preference for higher-rated music']\n",
       " I have a strong preference for alternative rock and Britpop music, valuing emotional depth and imaginative songwriting in the tracks I enjoy. My recent experiences indicate that I am inclined to favor higher-rated music, as seen in my appreciation for 'A Rush of Blood to the Head' for its iconic tracks and emotional resonance. Conversely, I tend to dislike music that, despite strong ratings, does not align with my genre preferences, as demonstrated by my reaction to 'Stripped.' These patterns suggest that my future choices will likely prioritize emotionally rich, highly-rated alternative rock and Britpop songs.,\n",
       " 'AECN6QWIL3UBQULDGIBOAIKOBUYQ': UserAgent(user_id=AECN6QWIL3UBQULDGIBOAIKOBUYQ)\n",
       " Long Term Memory: ['Preference for eclectic music blends', 'Interest in iconic albums from celebrated artists', 'Higher average ratings indicate broader appeal']\n",
       " Short Term Memory: [\"Liked 'Sign O' The Times' by Prince for its 4.8 rating\", \"Disliked 'Confessions on a Dance Floor' by Madonna despite its 4.7 rating\", 'Preference for timeless tracks that resonate with diverse tastes']\n",
       " I have a strong preference for eclectic music blends and iconic albums from celebrated artists, as evidenced by my appreciation for timeless tracks that resonate with diverse tastes. My recent interactions indicate a tendency to favor higher-rated items, such as my liking for 'Sign O' The Times' by Prince with its 4.8 rating, while I tend to dislike items that, despite high ratings like 'Confessions on a Dance Floor' by Madonna (4.7), do not align with my musical preferences. This suggests that I prioritize the emotional and cultural resonance of music over mere ratings when making future choices.,\n",
       " 'AFI3RJ3OU2LRGBVTXE6SVF3OIENQ': UserAgent(user_id=AFI3RJ3OU2LRGBVTXE6SVF3OIENQ)\n",
       " Long Term Memory: ['Preference for classic rock and nostalgic music', 'Value high average ratings and popularity', 'Appreciate affordable pricing for music items']\n",
       " Short Term Memory: [\"Liked 'All Over the World - The Very Best of Electric Light Orchestra' for its high rating and nostalgia\", \"Disliked 'Automatic For The People' despite its acclaim\", 'Recent focus on iconic tracks and affordability in music choices']\n",
       " I have a strong preference for classic rock and nostalgic music, often gravitating towards items with high average ratings and popularity. I appreciate affordable pricing for music items, which influences my purchasing decisions. Recently, I enjoyed 'All Over the World - The Very Best of Electric Light Orchestra' due to its high rating and nostalgic appeal, while I was disappointed by 'Automatic For The People' despite its acclaim. My current focus is on iconic tracks that are both well-rated and budget-friendly, guiding my future music choices.,\n",
       " 'AEZJWL6VYPYCJHK3HB2X5QBCCNVA': UserAgent(user_id=AEZJWL6VYPYCJHK3HB2X5QBCCNVA)\n",
       " Long Term Memory: ['Preference for albums with high average ratings', 'Appreciation for emotional depth and introspective lyrics', 'Interest in indie and alternative rock music']\n",
       " Short Term Memory: [\"Liked 'Mellon Collie and the Infinite Sadness' for its emotional depth\", \"Disliked 'Rock Steady' due to lower personal resonance\", 'Recent choice reflects preference for richer listening experiences']\n",
       " I have a strong preference for albums that feature high average ratings, particularly those that offer emotional depth and introspective lyrics. My interest lies primarily in indie and alternative rock music, as evidenced by my appreciation for albums like 'Mellon Collie and the Infinite Sadness,' which resonated with me due to its rich emotional content. Conversely, I tend to dislike albums that do not evoke a personal connection, such as 'Rock Steady.' This pattern suggests that I will likely continue to seek out music that provides a richer listening experience and aligns with my emotional and lyrical preferences.,\n",
       " 'AEKZGN6PWZKVEOZLRDBEWQH6P2FA': UserAgent(user_id=AEKZGN6PWZKVEOZLRDBEWQH6P2FA)\n",
       " Long Term Memory: ['Preference for classic rock music', 'Interest in high-quality sound production', 'Value historical significance in music']\n",
       " Short Term Memory: [\"Liked '2112' by Rush for its 4.8 rating and remastering\", \"Disliked 'Silver Side Up' by Nickelback despite its 4.7 rating\", 'Preference for albums with musical depth and historical context']\n",
       " I have a strong preference for classic rock music, particularly valuing high-quality sound production and the historical significance of albums. My recent interactions indicate a liking for musically rich and historically contextual works, as evidenced by my appreciation for Rush's '2112' due to its high rating and remastering, while I was less impressed by Nickelback's 'Silver Side Up' despite its favorable rating. This suggests that I am likely to continue favoring albums that offer depth and a meaningful connection to music history in my future choices.}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2user"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_base_310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
